{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_ostateczny (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "gf-vD_sosCJl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OHmnCP_DsCJu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def feat(image):\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    #kernel_h = np.array([3, 3])\n",
        "    kernel_h = [ \n",
        "        [-1, 0, 1], \n",
        "        [-1, 0, 1],\n",
        "        [-1, 0, 1]]\n",
        "    kernel_v = [ \n",
        "        [-1, 0, -1], \n",
        "        [-1, 0, -1],\n",
        "        [-1, 0, -1]]\n",
        "    input_placeholder_h = tf.placeholder(\n",
        "        dtype=tf.float32, shape=(1, image.shape[0], image.shape[1], 1))\n",
        "    input_placeholder_v = tf.placeholder(\n",
        "        dtype=tf.float32, shape=(1, 14, 14, 1))\n",
        "    \n",
        "    \n",
        "    with tf.name_scope('convolution'):\n",
        "        conv_w_h = tf.constant(kernel_h, dtype=tf.float32, shape=(3, 3, 1, 1)) \n",
        "        output_h = tf.nn.conv2d(input=input_placeholder_h, filter=conv_w_h, strides=[1, 2, 2, 1], padding='SAME', use_cudnn_on_gpu=True)\n",
        "\n",
        "        conv_w_v = tf.constant(kernel_v, dtype=tf.float32, shape=(3, 3, 1, 1)) \n",
        "        output_v = tf.nn.conv2d(input=input_placeholder_v, filter=conv_w_v, strides=[1, 2, 2, 1], padding='SAME', use_cudnn_on_gpu=True)\n",
        "        \n",
        "    with tf.Session() as sess:\n",
        "        result_h = sess.run(output_h, feed_dict={\n",
        "            input_placeholder_h: image[np.newaxis, :, :, np.newaxis]\n",
        "        })\n",
        "        res = result_h[0, :, :, 0]\n",
        "        result_v = sess.run(output_v, feed_dict={\n",
        "            input_placeholder_v: res[np.newaxis, :, :, np.newaxis]\n",
        "        })\n",
        "        return result_h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1LE5IHdJsCJ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#%matplotlib inline\n",
        "\n",
        "from ipywidgets import IntProgress\n",
        "from IPython.display import display\n",
        "\n",
        "max_count = len(mnist.train.images[:1000]) + len(mnist.test.images[:1000])\n",
        "f = IntProgress(min=0, max=max_count) # instantiate the bar\n",
        "display(f) # display the bar\n",
        "\n",
        "def extract_features(dataset):    \n",
        "    features = []\n",
        "    for i in range(len(dataset)):\n",
        "        f.value += 1\n",
        "        feature = []\n",
        "        img = dataset[i]\n",
        "        img.shape = (28, 28)\n",
        "        result = feat(img)\n",
        "        new_feature = []\n",
        "        for res in result[0, :, :, 0]:\n",
        "            for val in res:\n",
        "                new_feature.append(val)\n",
        "        features.append(new_feature)\n",
        "        \n",
        "    return features\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2V4v10xn53l3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_train_features = extract_features(mnist.train.images[:1000])\n",
        "new_test_features = extract_features(mnist.test.images[:1000])\n",
        "\n",
        "\n",
        "train_labels = mnist.train.labels[:1000]\n",
        "test_labels = mnist.test.labels[:1000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLiJSxO91Wpc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#shuffling arrays\n",
        "import random\n",
        "own_features = [*new_train_features[:1000], *new_test_features[:1000]]\n",
        "own_labels= [*train_labels[:1000],*test_labels[:1000]]\n",
        "test_features = mnist.test.images[:1000]\n",
        "train_features = mnist.train.images[:1000]\n",
        "no_extraction_features = [*train_features[:1000], *test_features[:1000]]\n",
        "\n",
        "\n",
        "def shuffle_features_and_labels(features,labels):\n",
        "  merged_arrays= list(zip(features,labels))\n",
        "  random.shuffle(merged_arrays)\n",
        "  return zip(*merged_arrays)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SEnPxAYSVvcZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#pca graph\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pca = PCA(n_components=30)\n",
        "print(own_features)\n",
        "pca.fit(own_features)\n",
        "pca_data = pca.transform(own_features)\n",
        "per_var=np.round(pca.explained_variance_ratio_*10, decimals=1)\n",
        "labels = [str(x) for x in range (1, len(per_var)+1)]\n",
        "plt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label=labels)\n",
        "plt.ylabel('Wartość własna czynnika')\n",
        "plt.xlabel('Czynnik')\n",
        "plt.title(\"Wartości własne czynników PCA\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJCRHBRN1Xzk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#cross validation\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "n_estimators= [10,20,50,100,200,500]\n",
        "for estimator in n_estimators:\n",
        "  scores =[]\n",
        "  for i in range(0,10):\n",
        "    features, labels = shuffle_features_and_labels(own_features,own_labels) # change own_features, to no_extraction_features for no cnn extraction\n",
        "    kf = KFold(n_splits=2)\n",
        "    rfc= RandomForestClassifier(estimator)\n",
        "    pca = PCA(n_components=100) \n",
        "    features =  StandardScaler().fit_transform(features) # comment for no normalization\n",
        "    features = pca.fit_transform(features)#comment for no pca\n",
        "\n",
        "    scores.append(np.mean(cross_val_score(rfc,features,labels,cv=2)))\n",
        "  print( str(estimator)+\": \" + str(np.mean(scores)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}